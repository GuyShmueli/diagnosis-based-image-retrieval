{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from together import Together\n",
    "from openai import OpenAI\n",
    "\n",
    "# togetherai_key = <insert togetherai key>\n",
    "together_client = Together(api_key=togetherai_key)\n",
    "\n",
    "# openai_key = <insert openai key>\n",
    "client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all JSONs\n",
    "\n",
    "with open ('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/ref_extractions.json', 'r') as f:\n",
    "    ref_extractions = json.load(f)\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/case_summary_pairs_list.json', 'r') as f:\n",
    "    case_summary_pairs_list = json.load(f)\n",
    "\n",
    "with open ('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/matching_uids_xml_paths.json', 'r') as f:\n",
    "    matching_uids_xml_paths = json.load(f)\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/citation_extrac_list.json', 'r') as f:\n",
    "    citation_list = json.load(f)\n",
    "\n",
    "with open ('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/matching_uids_pmid_list.json', 'r') as f:\n",
    "    matching_uids_pmid_list = json.load(f)\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/o3_mini_response_list.json', 'r') as f:\n",
    "    o3_mini_response_list = json.load(f)\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/indices_list.json', 'r') as f:\n",
    "    citation_valid_indices = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_indices_summaries_list(case_summary_pairs_list):\n",
    "    \"\"\"\n",
    "    Returns two lists:\n",
    "      - A list of indices corresponding to elements depicting both cases.\n",
    "      - A list of indices corresponding to elements depicting less than 2 cases.\n",
    "    \"\"\"\n",
    "    valid_indices = [idx for idx in range(len(case_summary_pairs_list)) if len(case_summary_pairs_list[idx]) == 2]\n",
    "    invalid_indices = [idx for idx in range(len(case_summary_pairs_list)) if len(case_summary_pairs_list[idx]) != 2]\n",
    "\n",
    "    return valid_indices, invalid_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_valid_indices, summaries_invalid_indices = calc_indices_summaries_list(case_summary_pairs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaries_invalid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/summaries_valid_indices.json', 'w') as f:\n",
    "#     json.dump(summaries_valid_indices, f)\n",
    "\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/summaries_valid_indices.json', 'r') as g:\n",
    "    summaries_valid_indices = json.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_indices(summaries_valid_indices, citation_valid_indices):\n",
    "    \"\"\"\n",
    "    Find the common indices between summaries_valid_indices and citation_valid_indices:\n",
    "      - summaries_valid_indices - represents the indices corresponding to successfully extracted case summaries (0-31,691) \n",
    "      - citation_valid_indices - represents the indices corresponding to successfully cited-citing pairs (0-31,691)\n",
    "    \"\"\"\n",
    "    summaries_valid_indices_set = set(summaries_valid_indices)\n",
    "    citation_valid_indices_set = set(citation_valid_indices)\n",
    "    common_indices = []\n",
    "\n",
    "    for i in range(len(matching_uids_pmid_list)):\n",
    "        if i in summaries_valid_indices_set and i in citation_valid_indices_set:\n",
    "            common_indices.append(i)\n",
    "    \n",
    "    return common_indices\n",
    "\n",
    "\n",
    "common_indices = find_common_indices(summaries_valid_indices, citation_valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/common_indices.json', 'w') as f:\n",
    "#     json.dump(common_indices, f)\n",
    "\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/common_indices.json', 'r') as g:\n",
    "    common_indices = json.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_valid_indices_dict = {citation_valid_indices[idx]: idx for idx in range(len(citation_valid_indices))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### citation_valid_indices_dict will not be saved as json because it turns the keys into strings (instead of ints) ###\n",
    "\n",
    "# # with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/citation_valid_indices_dict.json', 'w') as f:\n",
    "# #     json.dump(citation_valid_indices_dict, f)\n",
    "\n",
    "\n",
    "# with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/citation_valid_indices_dict.json', 'r') as g:\n",
    "#     citation_valid_indices_dict = json.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31080"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(citation_valid_indices_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of case summary pairs list is: 31692\n",
      "The length of o3 response list is: 31080\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of case summary pairs list is: {len(case_summary_pairs_list)}\")\n",
    "print(f\"The length of o3 response list is: {len(o3_mini_response_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6822",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m case1 \u001b[38;5;241m=\u001b[39m case_summary_pairs_list[curr_index][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m case2 \u001b[38;5;241m=\u001b[39m case_summary_pairs_list[curr_index][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m citation_reason \u001b[38;5;241m=\u001b[39m o3_mini_response_list[\u001b[43mcitation_valid_indices_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurr_index\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m      9\u001b[0m question_generating_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124mYou are an experienced clinician specializing in medical imaging. You will be given two cases and the reason for citation between the two (one case report cites the other), and asked to generate a set of comparative, clinically relevant questions that highlight both similarities and differences, helping differentiate potential diagnoses. Your questions should:\u001b[39m\n\u001b[1;32m     11\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m5. **Provide a subtitle specifying the level (1/2/3) of the current set of questions.**\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     33\u001b[0m question_generating_user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mBelow are two cases and the reason for citation between the two. Read them carefully, then generate a concise list of question prompts (in bullet or numbered format) that compare these cases on clinically meaningful aspects.\u001b[39m\n\u001b[1;32m     35\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124mProvide your final list of questions now.\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 6822"
     ]
    }
   ],
   "source": [
    "curr_index = common_indices[6663]\n",
    "\n",
    "case1 = case_summary_pairs_list[curr_index][0]\n",
    "\n",
    "case2 = case_summary_pairs_list[curr_index][1]\n",
    "\n",
    "citation_reason = o3_mini_response_list[citation_valid_indices_dict[curr_index]]\n",
    "\n",
    "question_generating_prompt = \"\"\"\n",
    "You are an experienced clinician specializing in medical imaging. You will be given two cases and the reason for citation between the two (one case report cites the other), and asked to generate a set of comparative, clinically relevant questions that highlight both similarities and differences, helping differentiate potential diagnoses. Your questions should:\n",
    "\n",
    "1. **Focus on Diagnostic Clues and Clinical Significance:**\n",
    "   - Avoid trivial or purely technical details (like minor differences in image orientation).\n",
    "   - Emphasize findings that inform diagnosis (e.g., presence of lesions, pattern of abnormalities, symptoms).\n",
    "\n",
    "2. **Use a Comparative Framing:**\n",
    "   - Explicitly compare Case A and Case B.\n",
    "   - Aim for questions that probe both common ground and distinguishing features.\n",
    "   - If possible, try asking mostly yes/no questions.\n",
    "\n",
    "3. **Follow a Hierarchical Reasoning Approach:**\n",
    "   - **Level 1 (Broad Context)**: Are both cases the same modality/organ system?\n",
    "   - **Level 2 (General Diagnosis Category)**: Are they both infectious, both neoplastic, etc.?\n",
    "   - **Level 3 (Specific Features & Findings)**: Detailed imaging findings (e.g., cavitation, consolidation, nodules), clinical presentation, organism type, etc.\n",
    "\n",
    "4. **Consider Step-by-Step Reasoning:**\n",
    "   - You may first silently analyze the diagnoses and imaging findings for each case.\n",
    "   - Then generate questions that a clinician would naturally ask to tease out whether the two cases have the same underlying pathology or different pathologies.\n",
    "\n",
    "5. **Provide a subtitle specifying the level (1/2/3) of the current set of questions.**\n",
    "\"\"\"\n",
    "\n",
    "question_generating_user = f\"\"\"\n",
    "Below are two cases and the reason for citation between the two. Read them carefully, then generate a concise list of question prompts (in bullet or numbered format) that compare these cases on clinically meaningful aspects.\n",
    "\n",
    "---\n",
    "Case A:\n",
    "{case1}\n",
    "\n",
    "Case B:\n",
    "{case2}\n",
    "\n",
    "Reason for Citation, Possible Similarities and Explanation:\n",
    "{citation_reason}\n",
    "---\n",
    "\n",
    "Now, **generate the list of comparative, clinically relevant questions** that a radiologist or physician might ask to determine whether these two cases share a diagnosis or differ in key features. \n",
    "\n",
    "Remember:\n",
    "- Maintain clinical depth: mention imaging findings, pathophysiology, or hallmark symptoms.\n",
    "- Emphasize similarities/differences that impact diagnosis.\n",
    "- Keep the questions focused and direct, as if you are performing a differential diagnosis.\n",
    "- Avoid vague or generic questions; ensure each question contributes to understanding diagnostic overlap or divergence.\n",
    "- Start with broad-level questions (anatomy, broad diagnosis similarity), then proceed to more specific questions about the nature of the condition, causative agents, imaging signs, etc.\n",
    "- Adhere to yes/no questions, if possible.\n",
    "- Provide a subtitle specifying the level (1/2/3) of each set of questions.\n",
    "\n",
    "Provide your final list of questions now.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citing_title': 'Secondary choroidal neovascularization due to choroidal osteoma after 9\\u2009years follow-up',\n",
       " 'citing_abstract': 'Background Choroidal osteoma is a benign intraocular tumor that can increase risk of developing choroidal neovascularization. The visual prognosis is influenced by the tumor location, decalcification status, overlying RPE atrophy, presence of choroidal neovascularization, persistence of subretinal fluid and occurrence of subretinal hemorrhages. Case presentation The authors present a 40-year-old woman diagnosed with choroidal osteoma of the right eye. Her best corrected visual acuity was 12/20 but decreased to 5/20 due to secondary choroidal neovascularization after 8\\u2009years follow up. Fundus examination revealed an enlarged choroidal osteoma in most margins at posterior pole with schistose hemorrhage beside macula. Optical coherence tomography angiography revealed unique features in the vascular changes of choroidal neovascularization in choroidal osteoma in the outer retinal layer and choroid capillary layers, and subretinal neovascularization. Indocyanine green fluorescence angiography showed there was hypo-fluorescence at the peripapillary with faint hyper-fluorescence at the macular, corresponding to the location on the fundus photograph. The patient received 3 injections of intravitreal ranibizumab. After 1\\u2009year follow up, her visual acuity of the right eye was 18/20 and the CNV had regressed. Conclusions We present the findings and treatment of a case of choroidal osteoma with secondary choroidal neovascularization. Optical coherence tomography angiography combined with FFA and ICGA is used to analysis the characteristics of secondary choroidal neovascularization. Optical coherence tomography angiography can reveal some unique characteristics in the vascular changes compared to fundus fluorescein angiography.',\n",
       " 'citation_paragraphs': ['There is no standard of treatment for choroidal osteomas in addition to observing, but therapies are directed for complications arising from CNV and subretinal fluid. There are some reports describe the clinical and diagnostic features of this tumor, some of them treat related CNV with photodynamic therapy or/and anti-vascular endothelial growth factor (anti-VEGF) [ 9 ,  10 ]. Some studies showed PDT had achieved success not only in the management of CNV secondary to choroidal osteoma but also preventing tumor growth toward the foveola [ 10 ,  11 ]. However, reperfusion following photodynamic therapy might lead to CNV formation and tumor decalcification [ 11 ,  12 ]. Furthermore, PDT may require more than once treatment and final visual acuity may decline [ 13 ]. In addition, thermal laser photocoagulation and transpupillary thermotherapy may have certain efficacy in cases of CNV secondary to choroidal osteoma while increasing retinal damage [ 5 ,  14 ,  15 ].',\n",
       "  'Another method of controlling CNV growth is intravitreal anti-VEGF. Our case was treated by anti-VEGF and stable for now, in spite of keeping indispensable monitoring. It is reported bevacizumab and ranibizumab have positive outcomes in both anatomy and visual acuity [ 9 ,  16 ]. The rapid regression of CNV secondary to CO may attributed to enhanced passage of the ranibizumab through the thinned and degenerated RPE and Bruch’s membrane to the subretinal area, thus increasing the drug’s efficacy [ 16 ].'],\n",
       " 'cited_title': 'Choroidal Osteoma and Secondary Choroidal Neovascularization Treated with Ranibizumab',\n",
       " 'cited_abstract': 'A 47-year-old female patient presented with a complaint of decreased vision in the right eye. Her visual acuity was 0.16 in the right eye and 1.0 in the left eye. Fundus examination revealed a slightly elevated, yellowish-white lesion with regular borders at the macula of the right eye. Early and late hyperfluorescence related with choroidal neovascularization (CNV) was detected in the right eye on fundus fluorescein angiography. B-scan ultrasonography revealed a hyperechoic choroidal lesion with acoustic shadowing. The lesion was diagnosed as choroidal osteoma. The patient received 3 injections of intravitreal ranibizumab. After 4 months, the visual acuity of the right eye was 0.9 and the CNV had regressed. Follow-up at about 7 months revealed reduced visual acuity in the right eye with an increase in subretinal fluid. An additional ranibizumab injection was administered. In this case report, we discuss the findings and treatment of a rare case of choroidal osteoma with secondary CNV.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generating_prompt = \"\"\"\n",
    "You are an experienced clinician specializing in medical imaging. You will be given two cases and the reason for citation between the two (one case report cites the other), and asked to generate a set of comparative, clinically relevant questions that highlight both similarities and differences, helping differentiate potential diagnoses. Your questions should:\n",
    "\n",
    "1. **Focus on Diagnostic Clues and Clinical Significance:**\n",
    "   - Avoid trivial or purely technical details (like minor differences in image orientation).\n",
    "   - Emphasize findings that inform diagnosis (e.g., presence of lesions, pattern of abnormalities, symptoms).\n",
    "\n",
    "2. **Use a Comparative Framing:**\n",
    "   - Explicitly compare Case A and Case B.\n",
    "   - Aim for questions that probe both common ground and distinguishing features.\n",
    "   - If possible, try asking mostly yes/no questions.\n",
    "\n",
    "3. **Follow a Hierarchical Reasoning Approach:**\n",
    "   - **Level 1 (Broad Context)**: Are both cases the same modality/organ system?\n",
    "   - **Level 2 (General Diagnosis Category)**: Are they both infectious, both neoplastic, etc.?\n",
    "   - **Level 3 (Specific Features & Findings)**: Detailed imaging findings (e.g., cavitation, consolidation, nodules), clinical presentation, organism type, etc.\n",
    "\n",
    "4. **Consider Step-by-Step Reasoning:**\n",
    "   - You may first silently analyze the diagnoses and imaging findings for each case.\n",
    "   - Then generate questions that a clinician would naturally ask to tease out whether the two cases have the same underlying pathology or different pathologies.\n",
    "\n",
    "5. **Provide a subtitle specifying the level (1/2/3) of the current set of questions.**\n",
    "\"\"\"\n",
    "\n",
    "question_generating_user = f\"\"\"\n",
    "Below are two cases and the reason for citation between the two. Read them carefully, then generate a concise list of question prompts (in numbered format) that compare these cases on clinically meaningful aspects.\n",
    "\n",
    "---\n",
    "Case A:\n",
    "%s\n",
    "\n",
    "Case B:\n",
    "%s\n",
    "\n",
    "Reason for Citation, Possible Similarities and Explanation:\n",
    "%s\n",
    "---\n",
    "\n",
    "Now, **generate the list of comparative, clinically relevant questions** that a radiologist or physician might ask to determine whether these two cases share a diagnosis or differ in key features. \n",
    "\n",
    "Remember:\n",
    "- Maintain clinical depth: mention imaging findings, pathophysiology, or hallmark symptoms.\n",
    "- Emphasize similarities/differences that impact diagnosis.\n",
    "- Keep the questions focused and direct, as if you are performing a differential diagnosis.\n",
    "- Avoid vague or generic questions; ensure each question contributes to understanding diagnostic overlap or divergence.\n",
    "- Start with broad-level questions (anatomy, broad diagnosis similarity), then proceed to more specific questions about the nature of the condition, causative agents, imaging signs, etc.\n",
    "- Adhere to yes/no questions, if possible.\n",
    "- Provide a subtitle specifying the level (1/2/3) of each set of questions.\n",
    "\n",
    "Provide your final list of questions now.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file is 338579405 bytes.\n",
      "The batch input file should be maximum 209715200 for the o3-mini model, hence we need 2 batches.\n"
     ]
    }
   ],
   "source": [
    "### Check the size of the complete jsonl (before splitting it) ###\n",
    "import os\n",
    "file_size = os.path.getsize(\"/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/questions_batch_requests.jsonl\")\n",
    "print(f\"The file is {file_size} bytes.\")\n",
    "print(f\"The batch input file should be maximum 209715200 for the o3-mini model, hence we need {int(file_size / 209715200) + 1} batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/questions_batch_requests_A.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, curr_index in enumerate(common_indices[:16000], start=1):\n",
    "\n",
    "        case1 = case_summary_pairs_list[curr_index][0]\n",
    "        case2 = case_summary_pairs_list[curr_index][1]\n",
    "        citation_reason = o3_mini_response_list[citation_valid_indices_dict[curr_index]]\n",
    "\n",
    "\n",
    "        request_obj = {\n",
    "            \"custom_id\": f\"request-{i}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"o3-mini\",\n",
    "                \"reasoning_effort\": \"low\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"developer\", \"content\": question_generating_prompt},\n",
    "                    {\"role\": \"user\", \"content\": question_generating_user % (case1, case2, citation_reason)}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        # Write each object on a new line in the JSONL file\n",
    "        f.write(json.dumps(request_obj, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/questions_batch_requests_A.jsonl\", 'r') as g:\n",
    "    questions_requests_list_A = [json.loads(line) for line in g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'custom_id': 'request-16000',\n",
       " 'method': 'POST',\n",
       " 'url': '/v1/chat/completions',\n",
       " 'body': {'model': 'o3-mini',\n",
       "  'reasoning_effort': 'low',\n",
       "  'messages': [{'role': 'developer',\n",
       "    'content': '\\nYou are an experienced clinician specializing in medical imaging. You will be given two cases and the reason for citation between the two (one case report cites the other), and asked to generate a set of comparative, clinically relevant questions that highlight both similarities and differences, helping differentiate potential diagnoses. Your questions should:\\n\\n1. **Focus on Diagnostic Clues and Clinical Significance:**\\n   - Avoid trivial or purely technical details (like minor differences in image orientation).\\n   - Emphasize findings that inform diagnosis (e.g., presence of lesions, pattern of abnormalities, symptoms).\\n\\n2. **Use a Comparative Framing:**\\n   - Explicitly compare Case A and Case B.\\n   - Aim for questions that probe both common ground and distinguishing features.\\n   - If possible, try asking mostly yes/no questions.\\n\\n3. **Follow a Hierarchical Reasoning Approach:**\\n   - **Level 1 (Broad Context)**: Are both cases the same modality/organ system?\\n   - **Level 2 (General Diagnosis Category)**: Are they both infectious, both neoplastic, etc.?\\n   - **Level 3 (Specific Features & Findings)**: Detailed imaging findings (e.g., cavitation, consolidation, nodules), clinical presentation, organism type, etc.\\n\\n4. **Consider Step-by-Step Reasoning:**\\n   - You may first silently analyze the diagnoses and imaging findings for each case.\\n   - Then generate questions that a clinician would naturally ask to tease out whether the two cases have the same underlying pathology or different pathologies.\\n\\n5. **Provide a subtitle specifying the level (1/2/3) of the current set of questions.**\\n'},\n",
       "   {'role': 'user',\n",
       "    'content': '\\nBelow are two cases and the reason for citation between the two. Read them carefully, then generate a concise list of question prompts (in bullet or numbered format) that compare these cases on clinically meaningful aspects.\\n\\n---\\nCase A:\\nA 5-year-old Caucasian female presented to the emergency room complaining of generalized abdominal pain that had started 18 hours prior to presentation accompanied with fever (39 ˚C), vomiting and constipation. Her past medical history was unremarkable. On physical examination, she was febrile, the abdomen was rigid and there was generalized severe tenderness. Digital rectal examination (DRE) showed soft stool without any blood. Her chest was clear. Laboratory tests were normal including Hemoglobin (Hb), White Blood Cells (WBC), Platelets (PLT), prothrombin time (PT), INR, Glucose, Creatinine, Urea, Na + , and K + . C - reactive protein (CRP) was elevated (134.5 mg/l). Through investigations, erect Abdominal X-RAY (AXR) showed air-fluid levels in the small bowel and dilated loops of the large bowel (Fig.  1 ). Erect AXR showing Air-Fluid levels and distended large bowel loops. Abdominal ultrasonography revealed a 5-cm hyperechoic mass in the hypogastric region surrounded by intestines (Fig.  2 ). Abdominal Ultrasonography showing a 5-cm hyperechoic mass above the bladder and surrounded by intestinal loops. Non-contrast abdominal computed tomography (non-contrast CT) demonstrated a high-density midline mass above the bladder (Fig.  3 ). Abdominal non-contrast CT scan showed hyperdensity mass above the bladder. These findings combined with clinical presentation suggest a case of bowel obstruction that turned out to acute abdomen pain. Therefore, we performed an exploratory laparotomy, and found a 5-cm cystic mass above the bladder, connected to the umbilicus with a purulent productive orifice (Fig.  4 ), there was purulent fluid between the intestinal loops (approximately 50 ml), and bowel loops were distended. Intraoperative view of the cyst with a purulent orifice. We performed complete excision of the mass. Methylene Blue Dye Injection in the bladder revealed no connection or fistula between the bladder and the mass. Pathology report of the excised specimen was compatible with Remnant of Urachus with acute suppurative inflammation, and no evidence of malignancy was noticed (Fig.  5 ). The mass cavity is lined by intestinal epithelium filled with purulent exudate infiltrating the wall that contains muscular layer. After surgery, the patient had a good condition and started oral nutrition on the next day.\\n\\nCase B:\\nA 54-year-old male with a history of alcohol abuse presented to the emergency with acute-onset, diffuse, cramping abdominal pain, worst in the epigastrium and lasting one day.\\xa0He denied fever, vomiting, loss of appetite or weight loss, diarrhea, constipation, or rectal bleeding, or any prior similar episodes. He had no prior abdominal surgeries. On examination, he was in distress and had moderate guarding and generalized tenderness with hypoactive bowel sounds. He was afebrile. Laboratory evaluation showed microcytic anemia and thrombocytopenia on complete blood count, hypokalemia on basic metabolic profile, and a normal lipase level (Table  1 ). Hb: hemoglobin; HCT: hematocrit; MCV: mean corpuscular volume; MCH: mean corpuscular hemoglobin; WBC: white blood cells; BUN: blood urea nitrogen Abdominal X-ray showed an evolving small bowel obstruction (Figure  1 ), which was confirmed by a CT scan of the abdomen and pelvis with contrast (Figure  2 ). On the same CT scan series, a urachal remnant with a superimposed mass lesion was depicted (Figures  3 ,  4 ). Arrows indicate dilated small bowel loops that suggest evolving small bowel obstruction Arrow\\xa0indicates air-fluid levels suggesting small bowel obstruction CT:\\xa0computed tomography Arrow indicates the presence of urachal remnant CT:\\xa0computed tomography Arrow indicates the presence of urachal remnant CT:\\xa0computed tomography A decision was made to go forward with an emergent surgery to release the small bowel obstruction. After receiving a platelet transfusion, the patient underwent an exploratory laparotomy. He was found to have a high-grade small bowel obstruction due to an extensive mass concerning for a malignancy. A frozen section was intraoperatively sent and read as adenocarcinoma (Figure  5 ). Arrows depict metastatic adenocarcinoma deposits in the peritoneum An incisional biopsy of the urachal mass was also sent. The final pathology specimen was reported as a moderately differentiated urachal adenocarcinoma (Figure  6 ) with positivity for CK20, CDX2, and CK7 (focal) stains (Figure  7 ). Arrows indicate urachal adenocarcinoma deposits The presence of brown staining in both slides suggests positive staining for CDX2 and CK20 The patient was staged at Stage IIID (Sheldon staging) due to the spread to local viscera other than the bladder. The tumor was deemed unresectable due to the involvement of multiple loops of the small bowel\\xa0and the mesentery of the small and large bowels. Systemic chemotherapy with 5-fluorouracil (5-FU), folinic acid, and oxaliplatin (modified FOLFOX-6) was initiated. The patient has received six cycles of chemotherapy so far. He has tolerated chemotherapy well enough and is still awaiting additional imaging to evaluate the response to therapy.\\n\\nReason for Citation, Possible Similarities and Explanation:\\nReason for Citation: To illustrate that urachal anomalies can present with acute abdominal symptoms requiring surgical intervention.  \\nPossible Similarities: Both cases involve urachal remnants leading to an acute abdomen scenario.  \\nExplanation: The citing paper references the infected urachal cyst case to highlight that aberrations of the urachal remnant may lead to sudden abdominal emergencies, even though the underlying etiologies are different, with one being an infection in a young patient and the other a malignant process in an older patient.  \\nConfidence: Medium\\n---\\n\\nNow, **generate the list of comparative, clinically relevant questions** that a radiologist or physician might ask to determine whether these two cases share a diagnosis or differ in key features. \\n\\nRemember:\\n- Maintain clinical depth: mention imaging findings, pathophysiology, or hallmark symptoms.\\n- Emphasize similarities/differences that impact diagnosis.\\n- Keep the questions focused and direct, as if you are performing a differential diagnosis.\\n- Avoid vague or generic questions; ensure each question contributes to understanding diagnostic overlap or divergence.\\n- Start with broad-level questions (anatomy, broad diagnosis similarity), then proceed to more specific questions about the nature of the condition, causative agents, imaging signs, etc.\\n- Adhere to yes/no questions, if possible.\\n- Provide a subtitle specifying the level (1/2/3) of each set of questions.\\n\\nProvide your final list of questions now.\\n'}]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_requests_list_A[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_batch_input_file_A = client.files.create(\n",
    "  file=open(\"/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/questions_batch_requests_A.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_67e15447b8808190b7d2ee82817379eb', completion_window='24h', created_at=1742820423, endpoint='/v1/chat/completions', input_file_id='file-8pzxWs2ygeLHv5TQS9H9t4', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742906823, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Generating Questions part A'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_batch_input_file_id_A = questions_batch_input_file_A.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=questions_batch_input_file_id_A,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"Generating Questions part A\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_67e15447b8808190b7d2ee82817379eb', completion_window='24h', created_at=1742820423, endpoint='/v1/chat/completions', input_file_id='file-8pzxWs2ygeLHv5TQS9H9t4', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1742825429, error_file_id=None, errors=None, expired_at=None, expires_at=1742906823, failed_at=None, finalizing_at=1742823579, in_progress_at=1742820436, metadata={'description': 'Generating Questions part A'}, output_file_id='file-EyYYFCpYtzgww7FgiKLPDs', request_counts=BatchRequestCounts(completed=16000, failed=0, total=16000))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(\"batch_67e15447b8808190b7d2ee82817379eb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content('file-EyYYFCpYtzgww7FgiKLPDs')\n",
    "file_response_text = file_response.text\n",
    "\n",
    "json_strings = file_response_text.strip().splitlines()\n",
    "\n",
    "# Parse each JSON string into a dictionary and store in a list\n",
    "response_dicts_A = [json.loads(line) for line in json_strings]\n",
    "\n",
    "generated_questions_A = [response_dicts_A[i]['response']['body']['choices'][0]['message']['content'] for i in range(len(response_dicts_A))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1: Broad Context and Modality  \n",
      "1. Do both Case A and Case B utilize CT imaging to evaluate for bowel-related pathology?  \n",
      "2. Are both cases focused on pathology within the colon?\n",
      "\n",
      "Level 2: General Diagnosis Category (Gallstone Ileus vs. Other Causes)  \n",
      "3. Do both cases present with findings suggestive of gallstone ileus resulting in bowel obstruction?  \n",
      "4. Are both cases associated with a history (or imaging evidence) of gallbladder disease that could predispose to gallstone migration?\n",
      "\n",
      "Level 3: Specific Imaging Findings and Clinical Features  \n",
      "5. Do both cases demonstrate the presence of an intraluminal calcified structure (gallstone) causing colonic obstruction?  \n",
      "6. Is pneumobilia or evidence of a cholecystoenteric fistula present in both cases?  \n",
      "7. Do both cases show signs of adjacent colonic wall thickening or ischemic changes secondary to the obstructing gallstone?  \n",
      "8. Were the clinical management decisions (surgical intervention vs. conservative management) influenced by the severity of imaging findings in both cases?\n"
     ]
    }
   ],
   "source": [
    "print(generated_questions_A[15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/generated_questions_A.json', 'w') as f:\n",
    "#     json.dump(generated_questions_A, f)\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/generated_questions_A.json', 'r') as f:\n",
    "    generated_questions_A = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_questions_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/questions_batch_requests_B.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, curr_index in enumerate(common_indices[16000:], start=16001):\n",
    "\n",
    "        case1 = case_summary_pairs_list[curr_index][0]\n",
    "        case2 = case_summary_pairs_list[curr_index][1]\n",
    "        citation_reason = o3_mini_response_list[citation_valid_indices_dict[curr_index]]\n",
    "\n",
    "\n",
    "        request_obj = {\n",
    "            \"custom_id\": f\"request-{i}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/chat/completions\",\n",
    "            \"body\": {\n",
    "                \"model\": \"o3-mini\",\n",
    "                \"reasoning_effort\": \"low\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"developer\", \"content\": question_generating_prompt},\n",
    "                    {\"role\": \"user\", \"content\": question_generating_user % (case1, case2, citation_reason)}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        # Write each object on a new line in the JSONL file\n",
    "        f.write(json.dumps(request_obj, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/questions_batch_requests_B.jsonl\", 'r') as g:\n",
    "    questions_requests_list_B = [json.loads(line) for line in g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_batch_input_file_B = client.files.create(\n",
    "  file=open(\"/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/questions_batch_requests_B.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_67e15e1f712c8190a32529b1476fb66e', completion_window='24h', created_at=1742822943, endpoint='/v1/chat/completions', input_file_id='file-Qnd24YRejqgz2aE3QTWVhT', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742909343, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'Generating Questions part B'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_batch_input_file_id_B = questions_batch_input_file_B.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=questions_batch_input_file_id_B,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"Generating Questions part B\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_67e15e1f712c8190a32529b1476fb66e', completion_window='24h', created_at=1742822943, endpoint='/v1/chat/completions', input_file_id='file-Qnd24YRejqgz2aE3QTWVhT', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1742826110, error_file_id=None, errors=None, expired_at=None, expires_at=1742909343, failed_at=None, finalizing_at=1742824911, in_progress_at=1742822949, metadata={'description': 'Generating Questions part B'}, output_file_id='file-EJ3Ee16SzqT3kVCzZowiLk', request_counts=BatchRequestCounts(completed=15002, failed=0, total=15002))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(\"batch_67e15e1f712c8190a32529b1476fb66e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content('file-EJ3Ee16SzqT3kVCzZowiLk')\n",
    "file_response_text = file_response.text\n",
    "\n",
    "json_strings = file_response_text.strip().splitlines()\n",
    "\n",
    "# Parse each JSON string into a dictionary and store in a list\n",
    "response_dicts_B = [json.loads(line) for line in json_strings]\n",
    "\n",
    "generated_questions_B = [response_dicts_B[i]['response']['body']['choices'][0]['message']['content'] for i in range(len(response_dicts_B))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/generated_questions_B.json', 'w') as f:\n",
    "#     json.dump(generated_questions_B, f)\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/generated_questions_B.json', 'r') as f:\n",
    "    generated_questions_B = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_questions_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the two lists into a single list\n",
    "generated_questions = generated_questions_A + generated_questions_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/generated_questions.json', 'w') as f:\n",
    "#     json.dump(generated_questions, f)\n",
    "\n",
    "with open('/cs/labs/tomhope/yuvalbus/pmc/pythonProject/largeListsGuy/generated_questions.json', 'r') as f:\n",
    "    generated_questions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31002"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
